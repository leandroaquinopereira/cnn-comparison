# -*- coding: utf-8 -*-
"""ZFNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MUajbK0veuMFMtOp33xu1ZJjR8irnaWs

# References

https://towardsdatascience.com/zfnet-an-explanation-of-paper-with-code-f1bd6752121d
"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import datetime
import os

tf.test.gpu_device_name() # GPU Test

image_size = (224, 224)
batch_size = 64

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/drive/MyDrive/dataset/train",
    label_mode = "categorical",
    validation_split=0.20,
    subset="training",
    seed=1337,
    image_size=image_size,
    batch_size=batch_size,
)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/drive/MyDrive/dataset/train",
    label_mode = "categorical",
    validation_split=0.20,
    subset="validation",
    seed=1337,
    image_size=image_size,
    batch_size=batch_size,
)
test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/drive/MyDrive/dataset/test",
    label_mode = "categorical",
#    validation_split=0.25,
#    subset="validation",
    seed=1337,
    image_size=image_size,
    batch_size=batch_size,
)

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
    ]
)

train_ds = train_ds.prefetch(buffer_size=32)
val_ds = val_ds.prefetch(buffer_size=32)

augmented_train_ds = train_ds.map(
  lambda x, y: (data_augmentation(x, training=True), y))

model = tf.keras.models.Sequential([                                                    
		tf.keras.layers.Conv2D(96, (7, 7), strides=(2, 2), activation='relu', input_shape=(224, 224, 3)),
		tf.keras.layers.MaxPooling2D(3, strides=2),
    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),
		tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), activation='relu'),
		tf.keras.layers.MaxPooling2D(3, strides=2),
    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),
		tf.keras.layers.Conv2D(384, (3, 3), activation='relu'),
		tf.keras.layers.Conv2D(384, (3, 3), activation='relu'),
		tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),
		tf.keras.layers.MaxPooling2D(3, strides=2),
    tf.keras.layers.Flatten(),
		tf.keras.layers.Dense(4096), #4096
		tf.keras.layers.Dense(4096), #4096
		tf.keras.layers.Dense(4, activation='softmax') #10
	])

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

epochs = 50

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))

callbacks = [
    tf.keras.callbacks.ModelCheckpoint("save_at_{epoch}.h5"),
    tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1),
    tf.keras.callbacks.EarlyStopping(patience=3),
]
model.compile(
    optimizer=keras.optimizers.Adam(1e-3),
    loss="categorical_crossentropy",
    metrics=['accuracy', 'binary_accuracy', 'categorical_accuracy', 
             'binary_crossentropy', 'categorical_crossentropy', 
             'kullback_leibler_divergence', 'poisson'],
)
model.fit(
    augmented_train_ds, 
    epochs=epochs, 
    callbacks=callbacks, 
    validation_data=val_ds,
)

model.evaluate(test_ds)